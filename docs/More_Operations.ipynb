{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*We spoke about the basic operations like **binding** and **bundling**, but the **sub-symbolic** level allows us to do other operations which are \"composite\" and have no equivalent in non VSA architecture, that is because we can use SDP Algebra as I mentioned.*\n",
    "\n",
    "\n",
    "## Analogy mapping\n",
    "\n",
    "Humans use analogy all the time, it is integral part of intelligence. What if I told you we can mimic a proto form of analogy on syb-symbolic level via vector math. Nooo waaay ! .... way!\n",
    "\n",
    "Here is the idea :\n",
    "\n",
    "$ analogy\\_map = relation * reverse\\_relation $\n",
    "\n",
    "if we do the algebraic manipulation :\n",
    "\n",
    "$ analogy\\_map * relation = reverse\\_relation $\n",
    "\n",
    "because the **bind** operation is two way street. \n",
    "\n",
    "Now we can use the first equation for a **training** operation and the second as **predicting/testing** operation.\n",
    "The important part is that we can do this operation on a whole **structure** too, not just on single term.\n",
    "Plus this is **one-shot** learning, something you can't do with Neuro-networks.\n",
    "\n",
    "Let concretize the idea, the relations we will pick are **\"above\"** and correspondingly the reverse **\"below\"**. We will train **\"analogical map\"** that will virtually \"swap\" the position of two relations i.e. make one relation transform to the other. \n",
    "Here is what we have :\n",
    "\n",
    "-- *circle above a square* --\n",
    "\n",
    "$ cas = above + a\\_role1 * circle + a\\_role2 * square $\n",
    "\n",
    "\n",
    "Let see the reverse :\n",
    "\n",
    "-- *square below a circle* --\n",
    "\n",
    "$ sbc = below + b\\_role1 * square + b\\_role2 * circle $\n",
    "\n",
    "\n",
    "Now we learn the mapping (one-shot learning) :\n",
    "\n",
    "$ map = cas * sbc $\n",
    "\n",
    "and then we can apply it to unknown (not trained with) objects. Lets define them, so that we can do the comparison.\n",
    "\n",
    "\n",
    "$ sat = above + a\\_role1 * star + a\\_role2 * triangle $\n",
    "\n",
    "$ tbs = below + b\\_role1 * triangle + b\\_role2 * star $\n",
    "\n",
    "So if we want to transform the \"triangle\" above the \"star' =to=> 'star' below 'triangle', we will bind it with the learned map. Of course it is approximate match. That is vectors for you.\n",
    "\n",
    "`tbs <=~=> map * sat`\n",
    "\n",
    "`sat <=~=> map * tbs`\n",
    "\n",
    "The operation works both ways. \n",
    "\n",
    "If you want it to work only in one direction you should use permutation-bind when defining (have not tested it).\n",
    "\n",
    "These kind of operations are also called **holistic transformations** where one compositional structure is mapped onto another compositional structure without having to first decompose the source representation into its components\n",
    "\n",
    "Ok now that we know the theory, let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bi import *\n",
    "from lexicon import *\n",
    "\n",
    "x = lex()\n",
    "x.add_items(['above', 'below', 'a1', 'a2', 'b1', 'b2', 'circle', 'square', 'star', 'triangle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We should use sdp.bundle(), instead of **+**, because of the even-oddity I mentioned earlier /adds too much noise and it may not work/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#training data\n",
    "cas = sdp.bundle([ x['above'], x['a1'] * x['circle'],   x['a2'] * x['square'] ])\n",
    "sbc = sdp.bundle([ x['below'], x['b1'] * x['square'],   x['b2'] * x['circle'] ])\n",
    "\n",
    "#novel/testing data\n",
    "sat = sdp.bundle([ x['above'], x['a1'] * x['star'],     x['a2'] * x['triangle'] ])\n",
    "tbs = sdp.bundle([ x['below'], x['b1'] * x['triangle'], x['b2'] * x['star'] ])\n",
    "\n",
    "#partially closer to the training data : 'square' is used in both at the same position\n",
    "sas = sdp.bundle([ x['above'], x['a1'] * x['star'],     x['a2'] * x['square'] ])\n",
    "sbs = sdp.bundle([ x['below'], x['b1'] * x['square'],   x['b2'] * x['star'] ])\n",
    "\n",
    "#misplased 'square' i.e. novel data\n",
    "sas2 = sdp.bundle([ x['above'], x['a1'] * x['square'],     x['a2'] * x['star'] ])\n",
    "sbs2 = sdp.bundle([ x['below'], x['b1'] * x['star'],   x['b2'] * x['square'] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets learn the map (one-shot learning) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M = cas * sbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "now test it against the training example (measuring distance, btw). Seems OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M * cas) % sbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets try against the test structure, which we did not use in training : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M * sat) % tbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In our case as we mentioned the mapping is bi-directional, so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M * tbs) % sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The same using sdp.dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.dist((M * sat), tbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The distance is ~38%, but we said that a distance below ~42% means that the symbols are similar (sdp.true_thresh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.sim((M * sat), tbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets also test it with data that partially match with the training data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.dist((M * sas), sbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The distance as expected is smaller ~25%. \n",
    "\n",
    "Once more but this time 'square' is placed in the 'wrong' position i.e. it will represent again in a sense novell data, ergo distance again becomes ~37%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3788"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.dist((M * sas2), sbs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And finally lets test against random SDP, to see if they are orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.dist((M * sat), sdp.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That ends our exploration of analogy mapping, but I suppose you can guess that there is big unexplored territory in the sub-symbolic space for other ways of building composite-operations on structures, if you follow the ideas described in this article. \n",
    "\n",
    "You can see more detailed test at **'test/analogy_mapping.py'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Categorization\n",
    "\n",
    "Another common human trait is **Categorization** or said it otherwise **Concept creation**.\n",
    "Here again **sub-symbolic** operations can help us.\n",
    "Lets try very rudimentary categorization.\n",
    "\n",
    "We have several instances of chairs and we want to crystallize from them the concept of 'chairs'. (BTW we can ground those symbols on NN-Labels as we did with the 'summing' example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.add_items(['wooden_chair', 'metal_chair', 'special_chair', 'wooden_table', 'chair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to be able to classify those chairs, by default as we know all the symbols are orthogonal. We need a way to make them more similar, for this reason we need an anchor that will serve the purpose of the **category** of **chairs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4987\n",
      "4918\n",
      "4927\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#chairs are orthogonal to the concept\n",
    "print x['wooden_chair'] % x['chair']\n",
    "print x['metal_chair'] % x['chair']\n",
    "\n",
    "print x['wooden_chair'] % x['metal_chair']\n",
    "print sdp.sim(x['wooden_chair'], x['metal_chair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the **bundle** operation aside from bundling also result in a vector closer to its operands (by hamming distance). \n",
    "\n",
    "So if we bundle every type of chair with the 'chair'-SDP we will move the vectors towards it, making them at the same time more similar themselves. (Of course if we use lexicon as we do here we have to update them using the **.set()** method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_wc = x['wooden_chair'] + x['chair']\n",
    "x.set('wooden_chair', new_wc)\n",
    "\n",
    "new_mc = x['metal_chair'] + x['chair']\n",
    "x.set('metal_chair', new_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare again :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3679\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print x['wooden_chair'] % x['metal_chair']\n",
    "print sdp.sim(x['wooden_chair'], x['metal_chair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the distance shrunk, both against the other chairs and the chair-concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465\n",
      "2458\n"
     ]
    }
   ],
   "source": [
    "print x['wooden_chair'] % x['chair']\n",
    "print x['metal_chair'] % x['chair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the modified chairs are still orthogonal to the rest of the symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5085\n",
      "5044\n"
     ]
    }
   ],
   "source": [
    "print x['wooden_chair'] % x['wooden_table']\n",
    "print x['metal_chair'] % x['wooden_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said this is rudimentary categorization, just to give you yet another idea of how to use the sub-symbolic  algebra. As I'm experimenting, I'm also contemplating a ways to integrate the SDP-algebra into the higher levels, such as the Prolog syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
